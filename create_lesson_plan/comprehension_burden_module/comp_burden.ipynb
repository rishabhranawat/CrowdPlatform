{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comprehension Burden for Sequencing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "import random as randomlib\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Knowledge Graph\n",
    "'''\n",
    "kg_path = \"../graph_query/graphs/knowledge_graph.gpickle\"\n",
    "kg = nx.read_gpickle(kg_path)\n",
    "kg_labels = [str(x) for x in list(kg.nodes())[1:]]\n",
    "n_labels = len(kg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_queries_based_on_node(node_label):\n",
    "    node = kg.node[node_label]\n",
    "\n",
    "    if(\"NodeType\" not in node): \n",
    "        kg.node[node_label][\"NodeType\"] = \"ConceptNode\"\n",
    "        l =  list(kg.neighbors(node_label))\n",
    "        return l\n",
    "    node_type = node[\"NodeType\"]\n",
    "    if(node_type == \"TopicNode\" or node_type == \"ConceptNode\"):\n",
    "        return list(kg.neighbors(node_label))\n",
    "    elif(node_type == \"SubConceptNode\"):\n",
    "        return [node_label]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    '''\n",
    "    Returns a list of queries depending on the type of the\n",
    "    node closest to the query.\n",
    "    args - query(str)\n",
    "    returns [] of str\n",
    "    '''\n",
    "def query_formulator(query, label):\n",
    "    queries = []\n",
    "    children_neighbours = get_queries_based_on_node(label)\n",
    "    queries = [label]\n",
    "    for child in children_neighbours:\n",
    "        queries.append(child)\n",
    "    return list(set(queries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get content from a given set of URLs.\n",
    "'''\n",
    "es_order = []\n",
    "def get_content():\n",
    "    f = open('user_study_dynamic_programming_engage.txt', 'r')\n",
    "    l = f.readlines()\n",
    "    docs = {}\n",
    "    index = {}\n",
    "    \n",
    "    counter = 0\n",
    "    for url in l:\n",
    "        try:\n",
    "            docs[url] = requests.get(url).content\n",
    "            index[url] = counter\n",
    "            es_order.append(url)\n",
    "            counter += 1\n",
    "        except:\n",
    "            continue\n",
    "    return docs, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Term Frequency Array for a particular document.\n",
    "'''\n",
    "def get_tfd(content):\n",
    "    word_count_dict = Counter(w for w in kg_labels \n",
    "                              if w.lower() in content.lower())\n",
    "    common = word_count_dict.most_common()\n",
    "    \n",
    "    frequency_arr = [0]*len(kg_labels)\n",
    "    \n",
    "    for common_word in common:\n",
    "        common_word_index = kg_labels.index(common_word[0])\n",
    "        frequency_arr[common_word_index] = common_word[1]\n",
    "    return frequency_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "content, index = get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Building word_data a document (rows) by term frequency (columns) matrix.\n",
    "'''\n",
    "tfd_data = {}\n",
    "for url, cont in content.items():\n",
    "    tfd_data[url] = get_tfd(cont)\n",
    "\n",
    "tfd_arr = []\n",
    "for key in index.keys():\n",
    "    tfd_arr.append(key.replace(\"\\n\", \"\"))\n",
    "\n",
    "word_data = {'TFD':tfd_arr}\n",
    "\n",
    "for label in kg_labels:\n",
    "    word_data[label] = [None]*len(index)\n",
    "\n",
    "for url, words_in_doc in tfd_data.items():\n",
    "    url_index = index[url]\n",
    "    for i in range(0, n_labels, 1):\n",
    "        word = kg_labels[i]\n",
    "        word_data[word][url_index] = words_in_doc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "(DTF)^T(DTF) = Coocurence Matrix\n",
    "'''\n",
    "document_term_frequency = pd.DataFrame(word_data).set_index('TFD')\n",
    "dtf_asint = document_term_frequency.astype(int)\n",
    "coocc = dtf_asint.T.dot(dtf_asint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calculating Relationship Score: S(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_relationship_between_concepts(concept_1, concept_2):\n",
    "    concept_1_index= document_term_frequency.columns.get_loc(concept_1)\n",
    "    concept_2_index= document_term_frequency.columns.get_loc(concept_2)\n",
    "    \n",
    "    return coocc.iloc[concept_1_index, concept_2_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Significance of a concept in a document: \\lambda(c, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_significance_score(concept, document):\n",
    "    if(document == None): return 0\n",
    "    concept_index = document_term_frequency.columns.get_loc(concept)\n",
    "    freq = dtf_asint.iloc[index[document]][concept_index]\n",
    "    coocc_row = coocc.iloc[concept_index,:] \n",
    "    r = np.array(coocc_row)\n",
    "    if(sum(r) == 0): return 0\n",
    "    return (freq)*np.count_nonzero(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_labels = ['Processes', 'Process Creation', 'Implementation of Processes', 'Modeling Multiprogramming', 'Process States','Process Termination']\n",
    "clustering_labels = ['Clustering', 'Spectral Clustering', 'K-Means', 'Unsupervised Learning']\n",
    "sorting_labels = ['Sorting']\n",
    "greedy_labels = ['Greedy Algorithms', 'Activity selection problem', 'Huffman codes']\n",
    "divide_and_conquer_labels = ['Divide and Conquer', 'Substitution method solving recurrences', 'Master method solving recurrences', u'Dfs', \n",
    "     \"Strassen's matrix multiplication\",'Maximum subarray', 'Recursion-tree method solving recurrences', u'Pca']\n",
    "graph_theory_labels = [\"Graph Theory\", \"Topological Sort\", \"Strongly Connected Components\",\n",
    "                      \"Depth-first search DFS\", \"Topological Sort\"]\n",
    "unsupervised_labels = ['Unsupervised Learning', u'Clustering', u'Spectral Clustering', 'K-means clustering', u'K-Means']\n",
    "supervised_learning_labels = ['Supervised Learning', 'Linear Algebra', 'Vectorization', 'Naive Bayes', 'Gaussian Discriminant Analysis', \n",
    "     'Logistic Regression', 'Support Vector Machines', 'Perceptron', 'Genearting Learning Algorithms']\n",
    "threads_labels = ['Threads', 'POSIX Threads', u'Bfs', 'Thread usage', 'Implementing Threads in User Space', 'Implementing Threads in the Kernel', \n",
    "                  'The Classical Thread Model', u'Kernel Methods', u'Memory Management']\n",
    "dp_labels = [\"Dynamic Programming\", \"Greedy Algorithms\", \"Dijkstra's algorithm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Key Sections k_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dp_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4ee7e2c66a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_formulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dp_labels' is not defined"
     ]
    }
   ],
   "source": [
    "relevant_concepts = set()\n",
    "\n",
    "key_doc = {}\n",
    "\n",
    "doc_to_key = {}\n",
    "\n",
    "labs = []\n",
    "q = dp_labels\n",
    "for each in q:\n",
    "    labs.extend(query_formulator(each, each))\n",
    "\n",
    "for each_document in content.keys():\n",
    "    rt = []\n",
    "    rc = []\n",
    "    for each_concept in labs:\n",
    "        s = get_significance_score(each_concept, each_document)\n",
    "        if(s > 0):\n",
    "            if(\"NodeType\" not in kg.node[each_concept]):\n",
    "                kg.node[each_concept][\"NodeType\"] = \"ConceptNode\"\n",
    "                rc.append((each_concept, s))\n",
    "            elif(kg.node[each_concept][\"NodeType\"] != \"TopicNode\" and \n",
    "               kg.node[each_concept][\"NodeType\"] != \"SubjectNode\" and\n",
    "              kg.node[each_concept][\"NodeType\"] != \"CourseNode\"):\n",
    "                rc.append((each_concept, s))\n",
    "            else:\n",
    "                if(kg.node[each_concept][\"NodeType\"] == \"TopicNode\"):\n",
    "                    rt.append((each_concept, s))\n",
    "    rt.sort(key=lambda x: x[1])\n",
    "    rt = rt[::-1]\n",
    "    \n",
    "    rc.sort(key=lambda x: x[1])\n",
    "    rc = rc[::-1]\n",
    "    if(len(rc)):\n",
    "        key_doc[each_document] = rc[0][0]\n",
    "        relevant_concepts.add(rc[0][0])\n",
    "        rc.pop(0)\n",
    "        counter = 0\n",
    "        while(counter < 10 and len(rc)):\n",
    "            relevant_concepts.add(rc[0][0])\n",
    "            rc.pop(0)\n",
    "            counter += 1\n",
    "    else:\n",
    "        if(len(rt)):\n",
    "            key_doc[each_document] = rt[0][0]\n",
    "            relevant_concepts.add(rt[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comprehension Burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def f_cb(sig_score, key_sig_score, relationship):\n",
    "    return key_sig_score\n",
    "\n",
    "def get_cb_document(document, document_key_concept, visited):\n",
    "    key_sig_score = get_significance_score(document_key_concept, document)\n",
    "    document_burden = 0.0\n",
    "    num_of_docs = 0\n",
    "    \n",
    "    order = list(relevant_concepts)\n",
    "    \n",
    "    for other_concept in order:\n",
    "        if(other_concept in visited or other_concept==document_key_concept): continue\n",
    "        sig_score = get_significance_score(other_concept, document)\n",
    "        relationship = get_relationship_between_concepts(document_key_concept, other_concept)\n",
    "        if(sig_score > 0): \n",
    "            document_burden += f_cb(sig_score, key_sig_score, relationship)\n",
    "            num_of_docs += 1\n",
    "    return document_burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Activity selection problem', 'Dynamic Programming', 'Rod cutting', 'Optimal binary search trees', \"Dijkstra's algorithm\", 'Huffman codes', 'Elements of dynamic programming', 'Longest common subsequence'])\n"
     ]
    }
   ],
   "source": [
    "print(relevant_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_linear(nodes):\n",
    "    parents = []\n",
    "    for each in nodes:\n",
    "        if(kg.nodes[each][\"NodeType\"] == \"TopicNode\"):\n",
    "            parents.append(each)\n",
    "    \n",
    "    linear = []\n",
    "    for p in parents:\n",
    "        linear.append(p)\n",
    "        children = kg.neighbors(p)\n",
    "        for c in children:\n",
    "            if c in nodes and kg.nodes[c][\"NodeType\"] == \"ConceptNode\":\n",
    "                linear.append(c)\n",
    "    \n",
    "    for each in nodes:\n",
    "        if each not in linear:\n",
    "            linear.append(each)\n",
    "    \n",
    "    return linear\n",
    "\n",
    "def get_bfs(nodes):\n",
    "    return []\n",
    "\n",
    "def get_random(nodes):\n",
    "    vals = list(nodes)\n",
    "    r = []\n",
    "    while(vals):\n",
    "        s = randomlib.choice(vals)\n",
    "        r.append(s)\n",
    "        vals.remove(s)\n",
    "    return r\n",
    "\n",
    "def get_es(nodes, key_doc):\n",
    "    order =[]\n",
    "    for each in es_order:\n",
    "        each = each.replace(\"\\n\", \"\")\n",
    "        \n",
    "        if(each in key_doc and key_doc[each] not in order):\n",
    "            order.append(key_doc[each])\n",
    "    for each in nodes:\n",
    "        if (each not in order):\n",
    "            order.append(each)\n",
    "    return order\n",
    "    \n",
    "def get_sequences(nodes, key_doc):\n",
    "        random = get_es(nodes, key_doc)\n",
    "        linear = get_linear(nodes)\n",
    "        top_down = linear[::-1]\n",
    "        return random, linear, top_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cp_score(order, doc_to_key):\n",
    "    visited = set()\n",
    "    total = 0\n",
    "    ordered = {}\n",
    "\n",
    "    for each in order: ordered[each] = []\n",
    "    for doc, kc in doc_to_key.items():\n",
    "        ordered[kc].append(doc)\n",
    "\n",
    "    for kc in order:\n",
    "        visited.add(kc)\n",
    "        docs = ordered[kc]\n",
    "        for each in docs:\n",
    "            total += get_cb_document(each, kc, visited)\n",
    "    print(total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longest common subsequence']\n",
      "969.0\n",
      "399.0\n",
      "830.0\n"
     ]
    }
   ],
   "source": [
    "es, linear, bottom_up = get_sequences(relevant_concepts, key_doc)\n",
    "\n",
    "get_cp_score(es, key_doc)\n",
    "get_cp_score(linear, key_doc)\n",
    "get_cp_score(bottom_up, key_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
