{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comprehension Burden for Sequencing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Knowledge Graph\n",
    "'''\n",
    "kg_path = \"../graph_query/graphs/knowledge_graph.gpickle\"\n",
    "kg = nx.read_gpickle(kg_path)\n",
    "kg_labels = [str(x) for x in list(kg.nodes())[1:]]\n",
    "n_labels = len(kg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get content from a given set of URLs.\n",
    "'''\n",
    "def get_content():\n",
    "    f = open('sample_urls.txt', 'r')\n",
    "    l = f.readlines()\n",
    "    docs = {}\n",
    "    index = {}\n",
    "    \n",
    "    counter = 0\n",
    "    for url in l:\n",
    "        docs[url] = requests.get(url).content\n",
    "        index[url] = counter\n",
    "        counter += 1\n",
    "    return docs, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Term Frequency Array for a particular document.\n",
    "'''\n",
    "def get_tfd(content):\n",
    "    word_count_dict = Counter(w for w in kg_labels \n",
    "                              if w.lower() in content.lower())\n",
    "    common = word_count_dict.most_common()\n",
    "    \n",
    "    frequency_arr = [0]*len(kg_labels)\n",
    "    \n",
    "    for common_word in common:\n",
    "        common_word_index = kg_labels.index(common_word[0])\n",
    "        frequency_arr[common_word_index] = common_word[1]\n",
    "    return frequency_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "content, index = get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Building word_data a document (rows) by term frequency (columns) matrix.\n",
    "'''\n",
    "tfd_data = {}\n",
    "for url, cont in content.items():\n",
    "    tfd_data[url] = get_tfd(cont)\n",
    "\n",
    "tfd_arr = []\n",
    "for key in index.keys():\n",
    "    tfd_arr.append(key.replace(\"\\n\", \"\"))\n",
    "\n",
    "word_data = {'TFD':tfd_arr}\n",
    "\n",
    "for label in kg_labels:\n",
    "    word_data[label] = [None]*len(index)\n",
    "\n",
    "for url, words_in_doc in tfd_data.items():\n",
    "    url_index = index[url]\n",
    "    for i in range(0, n_labels, 1):\n",
    "        word = kg_labels[i]\n",
    "        word_data[word][url_index] = words_in_doc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "(DTF)^T(DTF) = Coocurence Matrix\n",
    "'''\n",
    "document_term_frequency = pd.DataFrame(word_data).set_index('TFD')\n",
    "dtf_asint = document_term_frequency.astype(int)\n",
    "coocc = dtf_asint.T.dot(dtf_asint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calculating Relationship Score: S(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_relationship_between_concepts(concept_1, concept_2):\n",
    "    concept_1_index= document_term_frequency.columns.get_loc(concept_1)\n",
    "    concept_2_index= document_term_frequency.columns.get_loc(concept_2)\n",
    "    \n",
    "    return coocc.iloc[concept_1_index, concept_2_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Significance of a concept in a document: \\lambda(c, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_significance_score(concept, document):\n",
    "    if(document == None): return 0\n",
    "    concept_index = document_term_frequency.columns.get_loc(concept)\n",
    "    freq = dtf_asint.iloc[index[document]][concept_index]\n",
    "    coocc_row = coocc.iloc[concept_index,:] \n",
    "    r = np.array(coocc_row)\n",
    "    if(sum(r) == 0): return 0\n",
    "    return (freq)+np.count_nonzero(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Key Sections k_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "13\n",
      "14\n",
      "9\n",
      "10\n",
      "18\n",
      "19\n",
      "9\n",
      "10\n",
      "18\n",
      "19\n",
      "10\n",
      "11\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "18\n",
      "19\n",
      "14\n",
      "15\n",
      "18\n",
      "19\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "key_doc = {}\n",
    "\n",
    "doc_to_key = {}\n",
    "\n",
    "# for each_document in content.keys():\n",
    "#     doc_max = 0\n",
    "#     doc_to_key[each_document] = []\n",
    "#     for each_concept in kg_labels:\n",
    "#         s= get_significance_score(each_concept, each_document)\n",
    "#         if(s > doc_max):\n",
    "#             doc_max = s\n",
    "#             doc_to_key[each_document] = (doc_max, each_concept)\n",
    "\n",
    "for each_concept in kg_labels:\n",
    "    key_max = 0\n",
    "    for each_document in content.keys():\n",
    "        s = get_significance_score(each_concept, each_document)\n",
    "        if(s > key_max and s > 4.0):\n",
    "            key_max = s\n",
    "    \n",
    "            key_doc[each_concept] = each_document\n",
    "\n",
    "for key, val in key_doc.items():\n",
    "    doc_to_key[val] = key\n",
    "\n",
    "for each in content.keys():\n",
    "    if(each and each not in doc_to_key):\n",
    "        doc_to_key[each] = 'Clustering'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comprehension Burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def f_cb(sig_score, key_sig_score, relationship):\n",
    "    return sig_score+key_sig_score+relationship\n",
    "\n",
    "def get_cb_document(document, document_key_concept, visited):\n",
    "    key_sig_score = get_significance_score(document_key_concept, document)\n",
    "    document_burden = 0.0\n",
    "    num_of_docs = 0\n",
    "    for other_concept in kg_labels:\n",
    "        if(other_concept in visited): continue\n",
    "        sig_score = get_significance_score(other_concept, document)\n",
    "        relationship = get_relationship_between_concepts(document_key_concept, other_concept)\n",
    "        if(sig_score > 0): \n",
    "            document_burden += f_cb(sig_score, key_sig_score, relationship)\n",
    "            num_of_docs += 1\n",
    "    return document_burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('https://msdn.microsoft.com/en-us/library/azure/dn905944.aspx\\n', 'Clustering', 544.0)\n",
      "('http://www.cs.utah.edu/~piyush/teaching/cs5350.html\\n', 'Clustering', 544.0)\n",
      "('https://shapeofdata.wordpress.com/2013/07/16/mixture-models/\\n', 'Mixture Models', 441.0)\n",
      "('https://en.wikipedia.org/wiki/MLPACK_(C%2B%2B_library)\\n', 'Clustering', 511.0)\n",
      "('http://scikit-learn.org/stable/modules/mixture.html\\n', 'Clustering', 512.0)\n",
      "('https://www.edureka.co/blog/k-means-clustering-algorithm/\\n', 'Operating Systems', 364.0)\n",
      "('https://en.wikipedia.org/wiki/Mixture_models\\n', 'Clustering', 482.0)\n",
      "('https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/readings\\n', 'Computer Science', 319.0)\n",
      "('https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/lecture-notes\\n', 'Clustering', 454.0)\n",
      "('https://stats.stackexchange.com/q/232500\\n', 'Clustering', 454.0)\n",
      "('http://www.powershow.com/view/21510b-MDU0M/EM_Algorithm_and_Mixture_of_Gaussians_powerpoint_ppt_presentation\\n', 'Mixture of Gaussians', 304.0)\n",
      "('https://stats.stackexchange.com/questions/198239/k-means-clustering-minimizes-conditional-variance\\n', 'Clustering', 426.0)\n",
      "('https://edurev.in/studytube/A-GenerativeDiscriminative-Learning-Algorithm-for-Image-Classification-Research-Paper/80593ef0-e079-4f45-861b-843c9bb46fcf_p\\n', 'Clustering', 426.0)\n",
      "('https://en.wikipedia.org/wiki/Adaptive_resonance_theory\\n', 'Clustering', 426.0)\n",
      "('https://stats.stackexchange.com/q/63320\\n', 'Clustering', 426.0)\n"
     ]
    }
   ],
   "source": [
    "visited = set()\n",
    "for doc, kc in doc_to_key.items():\n",
    "    visited.add(kc)\n",
    "    print(doc, kc, get_cb_document(doc, kc, visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
