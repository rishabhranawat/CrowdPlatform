{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension Burden for Sequencing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Knowledge Graph\n",
    "'''\n",
    "kg_path = \"../graph_query/graphs/knowledge_graph.gpickle\"\n",
    "kg = nx.read_gpickle(kg_path)\n",
    "kg_labels = [str(x) for x in list(kg.nodes())[1:]]\n",
    "n_labels = len(kg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get content from a given set of URLs.\n",
    "'''\n",
    "def get_content():\n",
    "    f = open('sample_urls.txt', 'r')\n",
    "    l = f.readlines()\n",
    "    docs = {}\n",
    "    index = {}\n",
    "    \n",
    "    counter = 0\n",
    "    for url in l:\n",
    "        docs[url] = requests.get(url).content\n",
    "        index[url] = counter\n",
    "        counter += 1\n",
    "    return docs, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Relationship Score: S(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Term Frequency Array for a particular document.\n",
    "'''\n",
    "def get_tfd(content):\n",
    "    word_count_dict = Counter(w for w in kg_labels \n",
    "                              if w.lower() in content.lower())\n",
    "    common = word_count_dict.most_common()\n",
    "    \n",
    "    frequency_arr = [0]*len(kg_labels)\n",
    "    \n",
    "    for common_word in common:\n",
    "        common_word_index = kg_labels.index(common_word[0])\n",
    "        frequency_arr[common_word_index] = common_word[1]\n",
    "    return frequency_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "content, index = get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Building word_data a document (rows) by term frequency (columns) matrix.\n",
    "'''\n",
    "tfd_data = {}\n",
    "for url, cont in content.items():\n",
    "    tfd_data[url] = get_tfd(cont)\n",
    "\n",
    "tfd_arr = []\n",
    "for key in index.keys():\n",
    "    tfd_arr.append(key.replace(\"\\n\", \"\"))\n",
    "\n",
    "word_data = {'TFD':tfd_arr}\n",
    "\n",
    "for label in kg_labels:\n",
    "    word_data[label] = [None]*len(index)\n",
    "\n",
    "for url, words_in_doc in tfd_data.items():\n",
    "    url_index = index[url]\n",
    "    for i in range(0, n_labels, 1):\n",
    "        word = kg_labels[i]\n",
    "        word_data[word][url_index] = words_in_doc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "(DTF)^T(DTF) = Coocurence Matrix\n",
    "'''\n",
    "document_term_frequency = pd.DataFrame(word_data).set_index('TFD')\n",
    "dtf_asint = document_term_frequency.astype(int)\n",
    "coocc = dtf_asint.T.dot(dtf_asint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Significance of a concept in a document: \\lambda(c, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_significance_score(concept, document):\n",
    "    concept_index = document_term_frequency.columns.get_loc(concept)\n",
    "    freq = dtf_asint.iloc[index[document]][concept_index]\n",
    "    coocc_row = coocc.iloc[concept_index,:] \n",
    "    r = np.array(coocc_row)\n",
    "    return freq+0.3*np.count_nonzero(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Key Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "key_doc = {}\n",
    "\n",
    "for each_concept in kg_labels:\n",
    "    key_doc[each_concept] = None\n",
    "    key_max = 0\n",
    "    for each_document in content.keys():\n",
    "        s = get_significance_score(each_concept, each_document)\n",
    "        if(s > key_max):\n",
    "            key_max = s\n",
    "            key_doc[each_concept] = each_document\n",
    "\n",
    "# for key, val in key_doc.items():\n",
    "#     if(val != None):\n",
    "#         print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension Burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
