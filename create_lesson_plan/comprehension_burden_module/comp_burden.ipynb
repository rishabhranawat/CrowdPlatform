{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comprehension Burden for Sequencing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "import random as randomlib\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Knowledge Graph\n",
    "'''\n",
    "kg_path = \"../graph_query/graphs/knowledge_graph.gpickle\"\n",
    "kg = nx.read_gpickle(kg_path)\n",
    "kg_labels = [str(x) for x in list(kg.nodes())[1:]]\n",
    "n_labels = len(kg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_queries_based_on_node(node_label):\n",
    "    node = kg.node[node_label]\n",
    "    \n",
    "    node_type = node[\"NodeType\"]\n",
    "\n",
    "    if(node_type == \"TopicNode\" or node_type == \"ConceptNode\"):\n",
    "        return list(kg.neighbors(node_label))\n",
    "    elif(node_type == \"SubConceptNode\"):\n",
    "        return [node_label]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    '''\n",
    "    Returns a list of queries depending on the type of the\n",
    "    node closest to the query.\n",
    "    args - query(str)\n",
    "    returns [] of str\n",
    "    '''\n",
    "def query_formulator(query, label):\n",
    "    queries = []\n",
    "    children_neighbours = get_queries_based_on_node(label)\n",
    "    queries = [label]\n",
    "    for child in children_neighbours:\n",
    "        queries.append(child)\n",
    "    return list(set(queries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get content from a given set of URLs.\n",
    "'''\n",
    "def get_content():\n",
    "    f = open('user_study_dynamic_programming_engage.txt', 'r')\n",
    "    l = f.readlines()\n",
    "    docs = {}\n",
    "    index = {}\n",
    "    \n",
    "    counter = 0\n",
    "    for url in l:\n",
    "        docs[url] = requests.get(url).content\n",
    "        index[url] = counter\n",
    "        counter += 1\n",
    "    return docs, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Term Frequency Array for a particular document.\n",
    "'''\n",
    "def get_tfd(content):\n",
    "    word_count_dict = Counter(w for w in kg_labels \n",
    "                              if w.lower() in content.lower())\n",
    "    common = word_count_dict.most_common()\n",
    "    \n",
    "    frequency_arr = [0]*len(kg_labels)\n",
    "    \n",
    "    for common_word in common:\n",
    "        common_word_index = kg_labels.index(common_word[0])\n",
    "        frequency_arr[common_word_index] = common_word[1]\n",
    "    return frequency_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "content, index = get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Building word_data a document (rows) by term frequency (columns) matrix.\n",
    "'''\n",
    "tfd_data = {}\n",
    "for url, cont in content.items():\n",
    "    tfd_data[url] = get_tfd(cont)\n",
    "\n",
    "tfd_arr = []\n",
    "for key in index.keys():\n",
    "    tfd_arr.append(key.replace(\"\\n\", \"\"))\n",
    "\n",
    "word_data = {'TFD':tfd_arr}\n",
    "\n",
    "for label in kg_labels:\n",
    "    word_data[label] = [None]*len(index)\n",
    "\n",
    "for url, words_in_doc in tfd_data.items():\n",
    "    url_index = index[url]\n",
    "    for i in range(0, n_labels, 1):\n",
    "        word = kg_labels[i]\n",
    "        word_data[word][url_index] = words_in_doc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "(DTF)^T(DTF) = Coocurence Matrix\n",
    "'''\n",
    "document_term_frequency = pd.DataFrame(word_data).set_index('TFD')\n",
    "dtf_asint = document_term_frequency.astype(int)\n",
    "coocc = dtf_asint.T.dot(dtf_asint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calculating Relationship Score: S(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_relationship_between_concepts(concept_1, concept_2):\n",
    "    concept_1_index= document_term_frequency.columns.get_loc(concept_1)\n",
    "    concept_2_index= document_term_frequency.columns.get_loc(concept_2)\n",
    "    \n",
    "    return coocc.iloc[concept_1_index, concept_2_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Significance of a concept in a document: \\lambda(c, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_significance_score(concept, document):\n",
    "    if(document == None): return 0\n",
    "    concept_index = document_term_frequency.columns.get_loc(concept)\n",
    "    freq = dtf_asint.iloc[index[document]][concept_index]\n",
    "    coocc_row = coocc.iloc[concept_index,:] \n",
    "    r = np.array(coocc_row)\n",
    "    if(sum(r) == 0): return 0\n",
    "    return (freq)*np.count_nonzero(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Key Sections k_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "key_doc = {}\n",
    "\n",
    "doc_to_key = {}\n",
    "\n",
    "labs = []\n",
    "q = [\"Dynamic Programming\", \"Dijkstra's algorithm\"]\n",
    "for each in q:\n",
    "    labs.extend(query_formulator(each, each))\n",
    "    \n",
    "# labs.append(\"Greedy Algorithms\")\n",
    "# for each_concept in labs:\n",
    "#     key_max = 0\n",
    "#     for each_document in content.keys():\n",
    "#         s = get_significance_score(each_concept, each_document)\n",
    "#         if(s > key_max and s > 30):\n",
    "#             key_max = s\n",
    "#             key_doc[each_concept] = each_document\n",
    "\n",
    "# for key, val in key_doc.items():\n",
    "#     doc_to_key[val] = key\n",
    "\n",
    "for each_document in content.keys():\n",
    "    rt = []\n",
    "    rc = []\n",
    "    for each_concept in labs:\n",
    "        s = get_significance_score(each_concept, each_document)\n",
    "        if(s > 0):\n",
    "            if(kg.node[each_concept][\"NodeType\"] != \"TopicNode\" and \n",
    "               kg.node[each_concept][\"NodeType\"] != \"SubjectNode\" and\n",
    "              kg.node[each_concept][\"NodeType\"] != \"CourseNode\"):\n",
    "                rc.append((each_concept, s))\n",
    "            else:\n",
    "                if(kg.node[each_concept][\"NodeType\"] == \"TopicNode\"):\n",
    "                    rt.append((each_concept, s))\n",
    "    rt.sort(key=lambda x: x[1])\n",
    "    rt = rt[::-1]\n",
    "    \n",
    "    rc.sort(key=lambda x: x[1])\n",
    "    rc = rc[::-1]\n",
    "    if(len(rc)):\n",
    "        key_doc[each_document] = rc[0][0]\n",
    "    else:\n",
    "        if(len(rt)):\n",
    "            key_doc[each_document] = rt[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "relevant_concepts = set()\n",
    "for d, k in key_doc.items():\n",
    "    relevant_concepts.add(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comprehension Burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def f_cb(sig_score, key_sig_score, relationship):\n",
    "    return key_sig_score\n",
    "\n",
    "def get_cb_document(document, document_key_concept, visited):\n",
    "    key_sig_score = get_significance_score(document_key_concept, document)\n",
    "    document_burden = 0.0\n",
    "    num_of_docs = 0\n",
    "    \n",
    "    order = list(relevant_concepts)\n",
    "    \n",
    "    for other_concept in order:\n",
    "        if(other_concept in visited or other_concept==document_key_concept): continue\n",
    "        sig_score = get_significance_score(other_concept, document)\n",
    "        relationship = get_relationship_between_concepts(document_key_concept, other_concept)\n",
    "        if(sig_score > 0): \n",
    "            document_burden += f_cb(sig_score, key_sig_score, relationship)\n",
    "            num_of_docs += 1\n",
    "    return document_burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Dynamic Programming', 'Rod cutting', 'Longest common subsequence'])\n"
     ]
    }
   ],
   "source": [
    "print(relevant_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_linear(nodes):\n",
    "    parents = []\n",
    "    for each in nodes:\n",
    "        if(kg.nodes[each][\"NodeType\"] == \"TopicNode\"):\n",
    "            parents.append(each)\n",
    "    \n",
    "    linear = []\n",
    "    for p in parents:\n",
    "        linear.append(p)\n",
    "        children = kg.neighbors(p)\n",
    "        for c in children:\n",
    "            if c in nodes and kg.nodes[c][\"NodeType\"] == \"ConceptNode\":\n",
    "                linear.append(c)\n",
    "    \n",
    "    for each in nodes:\n",
    "        if each not in linear:\n",
    "            linear.append(each)\n",
    "    return linear\n",
    "\n",
    "def get_bfs(nodes):\n",
    "    \n",
    "    return []\n",
    "\n",
    "def get_random(nodes):\n",
    "    vals = list(nodes)\n",
    "    r = []\n",
    "    while(vals):\n",
    "        s = randomlib.choice(vals)\n",
    "        r.append(s)\n",
    "        vals.remove(s)\n",
    "    return r\n",
    "    \n",
    "\n",
    "def get_sequences(nodes):\n",
    "    \n",
    "        random = get_random(nodes)\n",
    "        linear = get_linear(nodes)\n",
    "        top_down = linear[::-1]\n",
    "        return random, linear, top_down\n",
    "    \n",
    "#     elif(topic == \"Memory Management\"):\n",
    "#         random = get_random(nodes)\n",
    "#         bfs = ['Memory Management','Computer Science', 'Graph Theory', 'Dfs', 'Supervised Learning', 'Pca', 'Minimum and Maximum']\n",
    "#         linear = ['Computer Science', 'Memory Management', 'Graph Theory', 'Dfs', 'Supervised Learning', 'Pca', 'Minimum and Maximum']\n",
    "#         top_down = linear[::-1]\n",
    "#         return random, linear, bfs, top_down\n",
    "#     elif(topic == \"Mixture Models\"):\n",
    "#         random = get_random(nodes)\n",
    "#         bfs = ['Memory Management','Computer Science', 'Graph Theory', 'Dfs', 'Supervised Learning', 'Pca', 'Minimum and Maximum']\n",
    "#         linear = ['Computer Science', 'Memory Management', 'Graph Theory', 'Dfs', 'Supervised Learning', 'Pca', 'Minimum and Maximum']\n",
    "#         random = linear[::-1]\n",
    "#         top_down = linear[::-1]\n",
    "#         return random, linear, bfs, top_down\n",
    "#     elif(topic == \"Dynamic Programming\"):\n",
    "#         random = get_random(nodes)\n",
    "#         bfs = [\"Dijkstra's algorithm\",'Depth First Search','Dynamic Programming','Analysis of Algorithms',\n",
    "#                'Linear Algebra','Operating Systems', \"Threads\"]\n",
    "#         linear = ['Analysis of Algorithms', 'Dynamic Programming', 'Depth First Search', \n",
    "#                   \"Dijkstra's algorithm\", 'Linear Algebra','Threads','Operating Systems']\n",
    "#         random = linear[::-1]\n",
    "#         top_down = linear[::-1]\n",
    "#         return random, linear, bfs, top_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cp_score(order, doc_to_key):\n",
    "    visited = set()\n",
    "    total = 0\n",
    "    ordered = {}\n",
    "\n",
    "    for each in order: ordered[each] = []\n",
    "    for doc, kc in doc_to_key.items():\n",
    "        ordered[kc].append(doc)\n",
    "\n",
    "    for kc in order:\n",
    "        visited.add(kc)\n",
    "        docs = ordered[kc]\n",
    "        for each in docs:\n",
    "            total += get_cb_document(each, kc, visited)\n",
    "    print(total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "669.0\n",
      "156.0\n"
     ]
    }
   ],
   "source": [
    "random, linear, bottom_up = get_sequences(relevant_concepts)\n",
    "get_cp_score(linear, key_doc)\n",
    "get_cp_score(bottom_up, key_doc)\n",
    "get_cp_score(random, key_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NodeType': 'ConceptNode'}\n"
     ]
    }
   ],
   "source": [
    "print(kg.node[\"Topological Sort\"])\n",
    "for each in kg.neighbors(\"Depth First Search\"): print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## linear with taking the weights of a particular node into consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
